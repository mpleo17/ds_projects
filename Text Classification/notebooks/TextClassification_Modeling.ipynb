{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c859c79-9e37-434e-acd9-3c67c33b08c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Add the project root to sys.path if not already there\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24d5c523-8d2c-4e99-974f-80de02bc8c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.data.data_loader import get_top_words, train_data, test_data, data_transformed\n",
    "from src.features.build_features import build_X\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy.stats import uniform, loguniform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cae92d1e-29d0-45f1-bcfb-05345086735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train and test data\n",
    "newsgroups_train = train_data()\n",
    "newsgroups_test = test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8ef5659-1fcb-4633-8c86-f61f4e6fca11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Text</th>\n",
       "      <th>Target Article Category</th>\n",
       "      <th>Article Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>A fair number of brave souls who upgraded thei...</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>1659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
       "      <td>sci.space</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>13</td>\n",
       "      <td>DN&gt; From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...</td>\n",
       "      <td>sci.med</td>\n",
       "      <td>1782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>4</td>\n",
       "      <td>I have a (very old) Mac 512k and a Mac Plus, b...</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>3</td>\n",
       "      <td>I just installed a DX2-66 CPU in a clone mothe...</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>1</td>\n",
       "      <td>\\nWouldn't this require a hyper-sphere.  In 3-...</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>8</td>\n",
       "      <td>Stolen from Pasadena between 4:30 and 6:30 pm ...</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11314 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Target                                               Text  \\\n",
       "0           7  I was wondering if anyone out there could enli...   \n",
       "1           4  A fair number of brave souls who upgraded thei...   \n",
       "2           4  well folks, my mac plus finally gave up the gh...   \n",
       "3           1  \\nDo you have Weitek's address/phone number?  ...   \n",
       "4          14  From article <C5owCB.n3p@world.std.com>, by to...   \n",
       "...       ...                                                ...   \n",
       "11309      13  DN> From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...   \n",
       "11310       4  I have a (very old) Mac 512k and a Mac Plus, b...   \n",
       "11311       3  I just installed a DX2-66 CPU in a clone mothe...   \n",
       "11312       1  \\nWouldn't this require a hyper-sphere.  In 3-...   \n",
       "11313       8  Stolen from Pasadena between 4:30 and 6:30 pm ...   \n",
       "\n",
       "        Target Article Category  Article Length  \n",
       "0                     rec.autos             475  \n",
       "1         comp.sys.mac.hardware             530  \n",
       "2         comp.sys.mac.hardware            1659  \n",
       "3                 comp.graphics              95  \n",
       "4                     sci.space             448  \n",
       "...                         ...             ...  \n",
       "11309                   sci.med            1782  \n",
       "11310     comp.sys.mac.hardware             674  \n",
       "11311  comp.sys.ibm.pc.hardware             581  \n",
       "11312             comp.graphics             311  \n",
       "11313           rec.motorcycles             321  \n",
       "\n",
       "[11314 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = data_transformed(data = newsgroups_train)\n",
    "df_test = data_transformed(data = newsgroups_test)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "192fa79d-ebad-43ac-a6a6-80b30ee87c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71acb11a-aca6-468d-8631-01b1c6b9b503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Time elapsed: 75.58800270000938\n",
      "\n",
      "Mean cross-validation accuracy with best parameters: 0.7592\n"
     ]
    }
   ],
   "source": [
    "# Complement Naive Bayes with custom feature\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_scaler', MinMaxScaler(), ['Article Length']), \n",
    "        ('text_vectorizer', TfidfVectorizer(), 'Text') \n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', ComplementNB())\n",
    "])\n",
    "\n",
    "param_distributions = {\n",
    "    'preprocessor__text_vectorizer__max_features': [30000, 48000, 50000], \n",
    "    'preprocessor__text_vectorizer__stop_words': ['english'],\n",
    "    'preprocessor__text_vectorizer__ngram_range': [(1, 1), (1, 2), (2, 2)], \n",
    "    'preprocessor__text_vectorizer__min_df': (1, 3, 5, 10), \n",
    "    'preprocessor__text_vectorizer__max_df': (0.2, 0.4, 0.6, 0.8, 1.0),\n",
    "    'preprocessor__text_vectorizer__norm': ('l1', 'l2'),\n",
    "    'classifier__alpha': np.logspace(-6, 6, 13)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=40,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "random_search.fit(df_train, df_train['Target Article Category'])\n",
    "print('Time elapsed: {}'.format(time.perf_counter() - t1))\n",
    "print(f\"\\nMean cross-validation accuracy with best parameters: {random_search.best_score_:.4f}\")\n",
    "\n",
    "model_metatdata = {\n",
    "    'model': random_search,\n",
    "    'metadata': {\n",
    "        'time_to_train': time.perf_counter() - t1,\n",
    "        'training_date': time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        'CV_score_best_model': random_search.best_score_,\n",
    "        'model_type': '*Complement Naive Bayes',\n",
    "        'hyperparameters': random_search.get_params()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31bdbc60-4946-4543-9b89-dd7b8bf221ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list.append(model_metatdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d02848f-0c68-49bc-a544-35b359cd10e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Time elapsed: 71.12886850000359\n",
      "\n",
      "Mean cross-validation accuracy with best parameters: 0.7591\n"
     ]
    }
   ],
   "source": [
    "# Complement Naive Bayes\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text_vectorizer', TfidfVectorizer(), 'Text') \n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', ComplementNB())\n",
    "])\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=40,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "random_search.fit(df_train, df_train['Target Article Category'])\n",
    "print('Time elapsed: {}'.format(time.perf_counter() - t1))\n",
    "print(f\"\\nMean cross-validation accuracy with best parameters: {random_search.best_score_:.4f}\")\n",
    "\n",
    "model_metatdata = {\n",
    "    'model': random_search,\n",
    "    'metadata': {\n",
    "        'time_to_train': time.perf_counter() - t1,\n",
    "        'training_date': time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        'CV_score_best_model': random_search.best_score_,\n",
    "        'model_type': 'Complement Naive Bayes',\n",
    "        'hyperparameters': random_search.get_params()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d75b935-373e-465c-a5bf-9a9c00c95919",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list.append(model_metatdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56fbb930-21d9-486f-b658-a07cd4227136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patel\\miniconda3\\envs\\midas_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 1546.5834833999397\n",
      "\n",
      "Mean cross-validation accuracy with best parameters: 0.7564\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model with custom feature\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_scaler', MinMaxScaler(), ['Article Length']), \n",
    "        ('text_vectorizer', TfidfVectorizer(), 'Text') \n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "param_distributions = {\n",
    "    'preprocessor__text_vectorizer__max_features': [30000, 48000, 50000], \n",
    "    'preprocessor__text_vectorizer__stop_words': ['english'],\n",
    "    'preprocessor__text_vectorizer__ngram_range': [(1, 1), (1, 2), (2, 2)], \n",
    "    'preprocessor__text_vectorizer__min_df': (1, 3, 5, 10), \n",
    "    'preprocessor__text_vectorizer__max_df': (0.2, 0.4, 0.6, 0.8, 1.0),\n",
    "    'preprocessor__text_vectorizer__norm': ('l1', 'l2'),\n",
    "    'classifier__C': uniform(loc=0.01, scale=100),\n",
    "    'classifier__penalty': ['l1', 'l2'], \n",
    "    'classifier__solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=40,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "random_search.fit(df_train, df_train['Target Article Category'])\n",
    "print('Time elapsed: {}'.format(time.perf_counter() - t1))\n",
    "print(f\"\\nMean cross-validation accuracy with best parameters: {random_search.best_score_:.4f}\")\n",
    "\n",
    "model_metatdata = {\n",
    "    'model': random_search,\n",
    "    'metadata': {\n",
    "        'time_to_train': time.perf_counter() - t1,\n",
    "        'training_date': time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        'CV_score_best_model': random_search.best_score_,\n",
    "        'model_type': '*Logistic Regression',\n",
    "        'hyperparameters': random_search.get_params()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "980bf4eb-5a76-4694-b0a6-87260ed9bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list.append(model_metatdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9456c8db-5b51-47cd-baf3-8e5a4d3874af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patel\\miniconda3\\envs\\midas_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 1585.1439401999814\n",
      "\n",
      "Mean cross-validation accuracy with best parameters: 0.7565\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[ \n",
    "        ('text_vectorizer', TfidfVectorizer(), 'Text') \n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "param_distributions = {\n",
    "    'preprocessor__text_vectorizer__max_features': [30000, 48000, 50000], \n",
    "    'preprocessor__text_vectorizer__stop_words': ['english'],\n",
    "    'preprocessor__text_vectorizer__ngram_range': [(1, 1), (1, 2), (2, 2)], \n",
    "    'preprocessor__text_vectorizer__min_df': (1, 3, 5, 10), \n",
    "    'preprocessor__text_vectorizer__max_df': (0.2, 0.4, 0.6, 0.8, 1.0),\n",
    "    'preprocessor__text_vectorizer__norm': ('l1', 'l2'),\n",
    "    'classifier__C': uniform(loc=0.01, scale=100),\n",
    "    'classifier__penalty': ['l1', 'l2'], \n",
    "    'classifier__solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=40,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "random_search.fit(df_train, df_train['Target Article Category'])\n",
    "print('Time elapsed: {}'.format(time.perf_counter() - t1))\n",
    "print(f\"\\nMean cross-validation accuracy with best parameters: {random_search.best_score_:.4f}\")\n",
    "\n",
    "model_metatdata = {\n",
    "    'model': random_search,\n",
    "    'metadata': {\n",
    "        'time_to_train': time.perf_counter() - t1,\n",
    "        'training_date': time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        'CV_score_best_model': random_search.best_score_,\n",
    "        'model_type': 'Logistic Regression',\n",
    "        'hyperparameters': random_search.get_params()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ddfcf66-4632-42b6-8af1-a0201fecb8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list.append(model_metatdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a7cd6d2-fd09-4027-94c3-688aa086075e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patel\\miniconda3\\envs\\midas_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 1382.1953193000518\n",
      "\n",
      "Mean cross-validation accuracy with best parameters: 0.7565\n"
     ]
    }
   ],
   "source": [
    "# SVC classifier with custom feature\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_scaler', MinMaxScaler(), ['Article Length']), \n",
    "        ('text_vectorizer', TfidfVectorizer(), 'Text') \n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LinearSVC(random_state=42, dual=False))\n",
    "])\n",
    "\n",
    "param_distributions = {\n",
    "    'preprocessor__text_vectorizer__max_features': [30000, 48000, 50000], \n",
    "    'preprocessor__text_vectorizer__stop_words': ['english'],\n",
    "    'preprocessor__text_vectorizer__ngram_range': [(1, 1), (1, 2), (2, 2)], \n",
    "    'preprocessor__text_vectorizer__min_df': (1, 3, 5, 10), \n",
    "    'preprocessor__text_vectorizer__max_df': (0.2, 0.4, 0.6, 0.8, 1.0),\n",
    "    'preprocessor__text_vectorizer__norm': ('l1', 'l2'),\n",
    "    'classifier__C': loguniform(0.01, 100),\n",
    "    'classifier__loss': ['squared_hinge'],\n",
    "    'classifier__penalty': ['l2'], \n",
    "    'classifier__tol': loguniform(1e-5, 1e-3)\n",
    "}\n",
    "\n",
    "random_search_ = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=40,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "random_search.fit(df_train, df_train['Target Article Category'])\n",
    "print('Time elapsed: {}'.format(time.perf_counter() - t1))\n",
    "print(f\"\\nMean cross-validation accuracy with best parameters: {random_search.best_score_:.4f}\")\n",
    "\n",
    "model_metatdata = {\n",
    "    'model': random_search,\n",
    "    'metadata': {\n",
    "        'time_to_train': time.perf_counter() - t1,\n",
    "        'training_date': time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        'CV_score_best_model': random_search.best_score_,\n",
    "        'model_type': '*SVM',\n",
    "        'hyperparameters': random_search.get_params()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c093c32e-4761-4474-850e-f7036a060b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list.append(model_metatdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97f1178b-ac6f-4146-82e1-3b38795b93d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Time elapsed: 137.74850159999914\n",
      "\n",
      "Mean cross-validation accuracy with best parameters: 0.7611\n"
     ]
    }
   ],
   "source": [
    "# SVC classifier\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text_vectorizer', TfidfVectorizer(), 'Text') \n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LinearSVC(random_state=42, dual=False))\n",
    "])\n",
    "\n",
    "param_distributions = {\n",
    "    'preprocessor__text_vectorizer__max_features': [30000, 48000, 50000], \n",
    "    'preprocessor__text_vectorizer__stop_words': ['english'],\n",
    "    'preprocessor__text_vectorizer__ngram_range': [(1, 1), (1, 2), (2, 2)], \n",
    "    'preprocessor__text_vectorizer__min_df': (1, 3, 5, 10), \n",
    "    'preprocessor__text_vectorizer__max_df': (0.2, 0.4, 0.6, 0.8, 1.0),\n",
    "    'preprocessor__text_vectorizer__norm': ('l1', 'l2'),\n",
    "    'classifier__C': loguniform(0.01, 100),\n",
    "    'classifier__loss': ['squared_hinge'],\n",
    "    'classifier__penalty': ['l2'], \n",
    "    'classifier__tol': loguniform(1e-5, 1e-3)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=40,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "random_search.fit(df_train, df_train['Target Article Category'])\n",
    "print('Time elapsed: {}'.format(time.perf_counter() - t1))\n",
    "print(f\"\\nMean cross-validation accuracy with best parameters: {random_search.best_score_:.4f}\")\n",
    "\n",
    "model_metatdata = {\n",
    "    'model': random_search,\n",
    "    'metadata': {\n",
    "        'time_to_train': time.perf_counter() - t1,\n",
    "        'training_date': time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        'CV_score_best_model': random_search.best_score_,\n",
    "        'model_type': 'SVM',\n",
    "        'hyperparameters': random_search.get_params()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3abab434-b5af-49a7-93bd-1a7b0c0acd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list.append(model_metatdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "000200cd-38f4-483d-a319-6a3ca582bd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patel\\miniconda3\\envs\\midas_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [0.06567122 0.07442106 0.06134006 0.08078468 0.07327296        nan\n",
      " 0.07574693        nan 0.16351447        nan 0.12754069 0.07380257\n",
      " 0.09183259 0.08714843 0.0740679  0.12709946        nan 0.12338699\n",
      " 0.07990102 0.09015352        nan        nan        nan 0.09342317\n",
      " 0.07150438 0.14309729 0.0705323  0.08308275 0.0726533         nan\n",
      "        nan 0.12930923 0.06602415 0.06063284        nan 0.09430675\n",
      " 0.07406751 0.11896765 0.10570907 0.08652974]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 89.87413700006437\n",
      "\n",
      "Mean cross-validation accuracy with best parameters: 0.1635\n"
     ]
    }
   ],
   "source": [
    "# KNN with custom features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_scaler', MinMaxScaler(), ['Article Length']), \n",
    "        ('text_vectorizer', TfidfVectorizer(), 'Text') \n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier',KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "param_distributions = {\n",
    "    'preprocessor__text_vectorizer__max_features': [5000, 10000, 20000], \n",
    "    'preprocessor__text_vectorizer__stop_words': ['english'],\n",
    "    'preprocessor__text_vectorizer__ngram_range': [(1, 1), (1, 2), (2, 2)], \n",
    "    'preprocessor__text_vectorizer__min_df': (1, 3, 5, 10), \n",
    "    'preprocessor__text_vectorizer__max_df': (0.2, 0.4, 0.6, 0.8, 1.0),\n",
    "    'preprocessor__text_vectorizer__norm': ('l1', 'l2'),\n",
    "    'classifier__n_neighbors': [50, 100, 200],\n",
    "    'classifier__weights': ['uniform', 'distance'],\n",
    "    'classifier__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], \n",
    "    'classifier__leaf_size': [10, 20, 30, 50, 100],\n",
    "    'classifier__p': [1, 2]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=40,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "random_search.fit(df_train, df_train['Target Article Category'])\n",
    "print('Time elapsed: {}'.format(time.perf_counter() - t1))\n",
    "print(f\"\\nMean cross-validation accuracy with best parameters: {random_search.best_score_:.4f}\")\n",
    "\n",
    "model_metatdata = {\n",
    "    'model': random_search,\n",
    "    'metadata': {\n",
    "        'time_to_train': time.perf_counter() - t1,\n",
    "        'training_date': time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        'CV_score_best_model': random_search.best_score_,\n",
    "        'model_type': '*KNN',\n",
    "        'hyperparameters': random_search.get_params()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2c05f6f-8822-45d2-9aa1-8a2d465613cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list.append(model_metatdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c82dbb6a-c3be-4a72-89c2-7fdb465bdabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patel\\miniconda3\\envs\\midas_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [0.05303164 0.05303172 0.05656701 0.0761887  0.07221133        nan\n",
      " 0.06708523        nan 0.16201118        nan 0.17129238 0.05303168\n",
      " 0.11949733 0.08370175 0.06717357 0.08511592        nan 0.07954727\n",
      " 0.07919427 0.09094951        nan        nan        nan 0.06575925\n",
      " 0.05329678 0.09307036 0.06735037 0.08714843 0.0529433         nan\n",
      "        nan 0.1247129  0.07194522 0.05957191        nan 0.10553255\n",
      " 0.05320848 0.1139295  0.11118899 0.09519132]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 87.49200219998602\n",
      "\n",
      "Mean cross-validation accuracy with best parameters: 0.1713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patel\\miniconda3\\envs\\midas_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:598: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    }
   ],
   "source": [
    "# KNN \n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text_vectorizer', TfidfVectorizer(), 'Text') \n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier',KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "param_distributions = {\n",
    "    'preprocessor__text_vectorizer__max_features': [5000, 10000, 20000], \n",
    "    'preprocessor__text_vectorizer__stop_words': ['english'],\n",
    "    'preprocessor__text_vectorizer__ngram_range': [(1, 1), (1, 2), (2, 2)], \n",
    "    'preprocessor__text_vectorizer__min_df': (1, 3, 5, 10), \n",
    "    'preprocessor__text_vectorizer__max_df': (0.2, 0.4, 0.6, 0.8, 1.0),\n",
    "    'preprocessor__text_vectorizer__norm': ('l1', 'l2'),\n",
    "    'classifier__n_neighbors': [50, 100, 200],\n",
    "    'classifier__weights': ['uniform', 'distance'],\n",
    "    'classifier__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], \n",
    "    'classifier__leaf_size': [10, 20, 30, 50, 100],\n",
    "    'classifier__p': [1, 2]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=40,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "random_search.fit(df_train, df_train['Target Article Category'])\n",
    "print('Time elapsed: {}'.format(time.perf_counter() - t1))\n",
    "print(f\"\\nMean cross-validation accuracy with best parameters: {random_search.best_score_:.4f}\")\n",
    "\n",
    "model_metatdata = {\n",
    "    'model': random_search,\n",
    "    'metadata': {\n",
    "        'time_to_train': time.perf_counter() - t1,\n",
    "        'training_date': time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        'CV_score_best_model': random_search.best_score_,\n",
    "        'model_type': 'KNN',\n",
    "        'hyperparameters': random_search.get_params()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e428ca18-2a5b-427d-b7da-8c3c05393ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list.append(model_metatdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e921735c-0a57-4e25-8218-8b51e42191b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['multiple_classification_models.joblib']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_filename = 'multiple_classification_models.joblib'\n",
    "joblib.dump(model_list, models_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
